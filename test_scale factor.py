import cv2
import numpy as np
import torch
import os
import sys
from ultralytics import YOLO
import time
import statistics
import math

# Model dosya yolunu tanÄ±mlayÄ±n
MODEL_PATH = os.path.join(os.path.dirname(__file__), "my_yolo_model.pt")

# Referans nesne boyutlarÄ± (cm cinsinden)
REFERENCE_OBJECTS = {
    "catal": {
        "length": 19.5,  # Ã‡atal uzunluÄŸu (cm)
        "width": 2.5,    # Ã‡atal geniÅŸliÄŸi (cm)
        "area": 48.75     # YaklaÅŸÄ±k alan (cmÂ²)
    },
    "kasik": {
        "length": 19.5,  # KaÅŸÄ±k uzunluÄŸu (cm)
        "width": 4.5,    # KaÅŸÄ±k geniÅŸliÄŸi (cm)
        "area": 87.75     # YaklaÅŸÄ±k alan (cmÂ²)
    }
}

# YOLO model yÃ¼kleme fonksiyonu
def load_yolo_model(model_path):
    try:
        # GPU kullanÄ±labilirliÄŸini kontrol et
        if not torch.cuda.is_available():
            print("UYARI: CUDA kullanÄ±lamÄ±yor. GPU bulunamadÄ± veya CUDA kurulu deÄŸil.")
            return None
        
        # GPU'yu zorla kullan
        device = torch.device("cuda")
        print(f"GPU kullanÄ±lacak: {torch.cuda.get_device_name(0)}")
        
        # Modeli GPU'ya yÃ¼kle
        model = YOLO(model_path)
        model.to(device)  # Modeli GPU'ya taÅŸÄ±
        
        # GPU kullanÄ±mÄ±nÄ± zorla
        torch.set_default_tensor_type('torch.cuda.FloatTensor')
        
        print(f"YOLO modeli baÅŸarÄ±yla GPU'ya yÃ¼klendi: {model_path}")
        return model
    except Exception as e:
        print(f"Model yÃ¼klenirken hata oluÅŸtu: {e}")
        return None

def calculate_scale_factor_from_bbox_area(reference_objects):
    """
    Calculate scale factor using the entire bounding box area of reference objects
    TR: Referans nesnelerin tÃ¼m sÄ±nÄ±rlayÄ±cÄ± kutu alanÄ±nÄ± kullanarak Ã¶lÃ§ek faktÃ¶rÃ¼ hesaplar.
    """
    scale_factors = []
    
    for obj in reference_objects:
        if obj["class"] in ["catal", "kasik"]:
            # Get reference object's real area in cmÂ²
            ref_area_cm2 = REFERENCE_OBJECTS[obj["class"]]["area"]
            
            # Get bounding box coordinates
            x1, y1, x2, y2 = obj["bbox"]
            
            # Calculate area of bounding box in pixelsÂ²
            bbox_area_px = (x2 - x1) * (y2 - y1)
            
            if bbox_area_px > 0:
                # Calculate cmÂ² per pixelÂ²
                scale_factor = ref_area_cm2 / bbox_area_px
                scale_factors.append(scale_factor)
                print(f"ğŸ” {obj['class']} - BBox: {bbox_area_px:.1f}pxÂ², GerÃ§ek: {ref_area_cm2}cmÂ², Scale: {scale_factor:.6f}")
    
    # Return median scale factor if reference objects found
    if scale_factors:
        median_scale = statistics.median(scale_factors)
        print(f"ğŸ“ Ã–lÃ§ek faktÃ¶rÃ¼ hesaplandÄ±: {median_scale:.6f} (bulunan faktÃ¶r sayÄ±sÄ±: {len(scale_factors)})")
        return median_scale
    
    # EÄŸer referans nesne yoksa None dÃ¶ndÃ¼r
    print("âš ï¸  UYARI: GeÃ§erli referans nesnesi bulunamadÄ± - Ã¶lÃ§ek faktÃ¶rÃ¼ hesaplanamÄ±yor")
    return None

def pixel_area_to_cm2(pixel_area, scale_factor):
    """
    Convert pixel area to cmÂ²
    TR: Piksel alanÄ±nÄ± cmÂ² cinsine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.
    """
    if scale_factor is None:
        # EÄŸer scale_factor yoksa, varsayÄ±lan bir deÄŸer kullan (Ã¶rneÄŸin 1 piksel = 0.1 cmÂ²)
        print("âš ï¸  UYARI: scale_factor None, varsayÄ±lan deÄŸer kullanÄ±lÄ±yor (1 piksel = 0.1 cmÂ²)")
        scale_factor = 0.1
    return pixel_area * scale_factor

def calculate_segment_area(segments):
    """
    Calculate area of segmentation polygon in pixels
    TR: Segmentasyon poligonunun alanÄ±nÄ± piksel cinsinden hesaplar.
    """
    if not segments or len(segments) < 3: # En az 3 nokta gerekli
        return 0.0
    
    # Kontrol: Segmentler [x, y] formatÄ±nda mÄ±?
    valid_segments = []
    for seg in segments:
        if isinstance(seg, list) and len(seg) == 2:
            valid_segments.append(seg)
    
    if len(valid_segments) < 3: # GeÃ§erli segment sayÄ±sÄ± kontrol
        return 0.0
    
    # Numpy dizisine dÃ¶nÃ¼ÅŸtÃ¼r
    points = np.array(valid_segments, dtype=np.int32)
    # Poligon alanÄ±nÄ± hesapla
    area = cv2.contourArea(points)
    return area

def process_detections_with_scale(results, scale_factor):
    """
    Process YOLO detection results and calculate real-world measurements
    TR: YOLO tespit sonuÃ§larÄ±nÄ± iÅŸler ve gerÃ§ek dÃ¼nya Ã¶lÃ§Ã¼mlerini hesaplar
    """
    reference_objects = []
    food_objects = []
    
    for result in results:
        boxes = result.boxes
        masks = result.masks
        
        if boxes is not None:
            for i, box in enumerate(boxes):
                # SÄ±nÄ±f bilgisi
                cls_id = int(box.cls.cpu().numpy())
                class_name = result.names[cls_id]
                confidence = float(box.conf.cpu().numpy())
                
                # Bounding box koordinatlarÄ±
                x1, y1, x2, y2 = box.xyxy.cpu().numpy()[0]
                bbox_area_px = (x2 - x1) * (y2 - y1)
                
                detection_info = {
                    "class": class_name,
                    "confidence": confidence,
                    "bbox": [x1, y1, x2, y2],
                    "bbox_area_px": bbox_area_px
                }
                
                # Segmentasyon alanÄ± varsa ekle
                if masks is not None and i < len(masks.xy):
                    # Segmentasyon poligonu
                    segments = masks.xy[i].tolist()
                    if segments:
                        segment_area_px = calculate_segment_area(segments)
                        detection_info["segments"] = segments
                        detection_info["segment_area_px"] = segment_area_px
                        
                        # GerÃ§ek dÃ¼nya alanÄ±nÄ± hesapla
                        if scale_factor is not None:
                            real_area_cm2 = pixel_area_to_cm2(segment_area_px, scale_factor)
                            detection_info["real_area_cm2"] = real_area_cm2
                
                # Referans nesneler ve yemek nesneleri ayÄ±r
                if class_name in ["catal", "kasik"]:
                    reference_objects.append(detection_info)
                else:
                    food_objects.append(detection_info)
    
    return reference_objects, food_objects

def webcam_detection(model):
    """Webcam Ã¼zerinden gerÃ§ek zamanlÄ± segmentasyon yapar"""
    # FarklÄ± kamera indekslerini dene
    camera_indices = [0, 1, 2]  # Daha fazla indeks ekleyebilirsiniz
    cap = None
    
    for idx in camera_indices:
        if idx == 0 or idx == 1:
            continue
        try:
            # DirectShow (dshow) backend'ini aÃ§Ä±kÃ§a belirterek deneyin
            cap = cv2.VideoCapture(idx, cv2.CAP_DSHOW)
            if cap.isOpened():
                print(f"Kamera indeksi {idx} ile baÅŸarÄ±yla aÃ§Ä±ldÄ±.")
                break
        except Exception as e:
            print(f"Kamera indeksi {idx} aÃ§Ä±lamadÄ±: {e}")
            
        try:
            # DirectShow olmadan deneyin
            cap = cv2.VideoCapture(idx)
            if cap.isOpened():
                print(f"Kamera indeksi {idx} ile baÅŸarÄ±yla aÃ§Ä±ldÄ± (backend belirtilmeden).")
                break
        except Exception as e:
            print(f"Kamera indeksi {idx} aÃ§Ä±lamadÄ± (backend belirtilmeden): {e}")
    
    if cap is None or not cap.isOpened():
        print("Webcam aÃ§Ä±lamadÄ±! HiÃ§bir kamera bulunamadÄ±.")
        return
    
    try:
        # Kamera Ã§Ã¶zÃ¼nÃ¼rlÃ¼ÄŸÃ¼nÃ¼ ayarlamaya Ã§alÄ±ÅŸ
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
    except Exception as e:
        print(f"Kamera Ã§Ã¶zÃ¼nÃ¼rlÃ¼ÄŸÃ¼ ayarlanamadÄ±: {e}")
    
    print("Webcam baÅŸlatÄ±ldÄ±. Ã‡Ä±kmak iÃ§in 'q' tuÅŸuna basÄ±n.")
    
    while True:
        try:
            # Frame'i oku
            ret, frame = cap.read()
            if not ret:
                print("Frame okunamadÄ±!")
                break
                
            # Performans takibi iÃ§in zaman baÅŸlangÄ±cÄ±
            start_time = time.time()
            
            # YOLO modeli ile tahmin yap
            results = model.predict(
                source=frame, 
                conf=0.25,          # GÃ¼ven eÅŸiÄŸi
                iou=0.45,           # IoU eÅŸiÄŸi
                show=False,         # GÃ¶sterme (Manuel gÃ¶stereceÄŸiz)
                stream=True,        # Stream modu
                retina_masks=True,  # Daha hassas maskeler
                verbose=False,      # Konsola bilgi yazdÄ±rma
                imgsz=640,           # Model giriÅŸ boyutu
                device='cuda'      # GPU kullanÄ±mÄ± iÃ§in
            )
            
            # Ä°lk olarak referans nesneleri tespit et ve scale factor hesapla
            results_list = list(results)
            reference_objects, food_objects = process_detections_with_scale(results_list, None)
            
            # Scale factor hesapla
            scale_factor = calculate_scale_factor_from_bbox_area(reference_objects) if reference_objects else None
            
            # EÄŸer scale factor hesaplandÄ±ysa, food objects iÃ§in gerÃ§ek alanlarÄ± hesapla
            if scale_factor is not None and food_objects:
                for food_obj in food_objects:
                    if "segment_area_px" in food_obj:
                        food_obj["real_area_cm2"] = pixel_area_to_cm2(food_obj["segment_area_px"], scale_factor)
            
            # SonuÃ§larÄ± iÅŸle ve gÃ¶rÃ¼ntÃ¼ Ã¼zerine Ã§iz
            for result in results_list:
                # Segmentasyon maskelerini ve sÄ±nÄ±rlayÄ±cÄ± kutularÄ± al
                boxes = result.boxes
                masks = result.masks
                
                # EÄŸer maskeler varsa
                if masks is not None:
                    # GÃ¶rÃ¼ntÃ¼ Ã¼zerine maskeleri Ã§iz
                    annotated_frame = result.plot()
                    
                    # FPS hesapla
                    fps = 1.0 / (time.time() - start_time)
                    
                    # FPS bilgisini ekle
                    cv2.putText(
                        annotated_frame, 
                        f"FPS: {fps:.1f}", 
                        (20, 40), 
                        cv2.FONT_HERSHEY_SIMPLEX, 
                        1, 
                        (0, 255, 0), 
                        2
                    )
                    
                    # Scale factor bilgisini gÃ¶ster
                    scale_text = f"Scale Factor: {scale_factor:.6f}" if scale_factor else "Scale Factor: N/A"
                    cv2.putText(
                        annotated_frame, 
                        scale_text, 
                        (20, 80), 
                        cv2.FONT_HERSHEY_SIMPLEX, 
                        0.7, 
                        (255, 255, 0), 
                        2
                    )
                    
                    # Referans nesne sayÄ±sÄ±nÄ± gÃ¶ster
                    ref_count_text = f"Reference Objects: {len(reference_objects)}"
                    cv2.putText(
                        annotated_frame, 
                        ref_count_text, 
                        (20, 110), 
                        cv2.FONT_HERSHEY_SIMPLEX, 
                        0.7, 
                        (255, 255, 0), 
                        2
                    )
                    
                    # Tespit edilen nesneler ve gerÃ§ek alanlarÄ±nÄ± gÃ¶ster
                    y_offset = 140
                    
                    # Referans nesneleri gÃ¶ster
                    for ref_obj in reference_objects:
                        text = f"{ref_obj['class']}: {ref_obj['bbox_area_px']:.1f}pxÂ²"
                        cv2.putText(
                            annotated_frame, 
                            text, 
                            (20, y_offset), 
                            cv2.FONT_HERSHEY_SIMPLEX, 
                            0.6, 
                            (0, 255, 255), 
                            2
                        )
                        y_offset += 25
                    
                    # Food nesneleri ve gerÃ§ek alanlarÄ±nÄ± gÃ¶ster
                    for food_obj in food_objects:
                        if "real_area_cm2" in food_obj:
                            text = f"{food_obj['class']}: {food_obj['segment_area_px']:.1f}pxÂ² = {food_obj['real_area_cm2']:.2f}cmÂ²"
                        else:
                            text = f"{food_obj['class']}: {food_obj.get('segment_area_px', food_obj['bbox_area_px']):.1f}pxÂ²"
                        cv2.putText(
                            annotated_frame, 
                            text, 
                            (20, y_offset), 
                            cv2.FONT_HERSHEY_SIMPLEX, 
                            0.6, 
                            (0, 255, 0), 
                            2
                        )
                        y_offset += 25
                    
                    # Ä°ÅŸlenmiÅŸ frame'i gÃ¶ster
                    cv2.imshow("YOLOv11s Scale Factor Test", annotated_frame)
                else:
                    # Herhangi bir maske bulunmazsa orijinal frame'i gÃ¶ster
                    cv2.imshow("YOLOv11s Scale Factor Test", frame)
        except Exception as e:
            print(f"Hata oluÅŸtu: {e}")
            break
            
        # 'q' tuÅŸuna basÄ±ldÄ±ÄŸÄ±nda Ã§Ä±k
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    
    # Temizle
    cap.release()
    cv2.destroyAllWindows()
    print("Webcam kapatÄ±ldÄ±.")

def main():
    print("YOLOv11s Real-Time Instance Segmentation")
    print("=========================================")
    
    # Modeli yÃ¼kle
    model = load_yolo_model(MODEL_PATH)
    if model is None:
        print("Model yÃ¼klenemedi. Program sonlandÄ±rÄ±lÄ±yor.")
        return
    
    # Real-time webcam detection baÅŸlat
    webcam_detection(model)
    
    print("Program sonlandÄ±rÄ±ldÄ±.")

if __name__ == "__main__":
    main()